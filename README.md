# Sequence Classification with Transformers
Sample code data to fine-tune commonly used transformer-based NLP models for sequence classification tasks. The code is written on Google Colab. 

1. "sample_data.xlsx":
   this file contains a sample of well-labeled sentences indicating whether the sentence is about a performance contributor or a performance detractor.
2. "sequence_classification.ipynb":
   this Jupyter notebook illustrates the steps of training transformers. I use three models as examples: BERT, GPT-2, and GPT-3. BERT and GPT-2 are open-sourced and provided by Hugging Face. You need an OpenAI API to access    GPT-3.

   
